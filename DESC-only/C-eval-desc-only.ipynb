{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d02288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_features(model_name):\n",
    "    return np.load(f'{model_name}_features.npz')['data']\n",
    "dt = pd.read_csv('subset-LA-even.csv')\n",
    "# Define the list of model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9658a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['distilroberta','bert-cased']#,'bert', 'bert-large', 'gpt2', 'roberta', 'roberta-large', 'xlnet', 'xlnet-large','albert','albert-large']#[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f838c360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilroberta (48714, 768)\n",
      "bert-cased (48714, 768)\n"
     ]
    }
   ],
   "source": [
    "for M in model_names:\n",
    "    NLP = load_features(M)\n",
    "    \n",
    "    print(M, NLP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f6ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1e236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt.fulltext[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d341d847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(dt.Severity)\n",
    "plt.xticks(np.arange(1,5),fontsize=16)\n",
    "plt.xlabel('Severity class',fontsize=18)\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0,6000,1000),fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('S-hist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cbc51ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for language model: distilroberta...\n",
      "distilroberta NLP\n",
      "Cross-validating Light GBM...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372769\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391852\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391852\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "Light GBM cross-validation complete. \n",
      "\tAverage Accuracy: 0.8676356778278602,\n",
      "\tAverage F1 Score: 0.8672825690293227,\n",
      "\tAverage Precision: 0.8714021563070299,\n",
      "\tAverage Recall: 0.8674583760607668\n",
      "\n",
      "Cross-validating K-Nearest Neighbors...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage Accuracy: 0.8484624747045195,\n",
      "\tAverage F1 Score: 0.8484222209368619,\n",
      "\tAverage Precision: 0.8528829230662268,\n",
      "\tAverage Recall: 0.8483271757127209\n",
      "\n",
      "Cross-validating Random Forest...\n",
      "Random Forest cross-validation complete. \n",
      "\tAverage Accuracy: 0.8574743404465759,\n",
      "\tAverage F1 Score: 0.8573519191987724,\n",
      "\tAverage Precision: 0.8620267221546914,\n",
      "\tAverage Recall: 0.857280948869029\n",
      "\n",
      "Cross-validating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:23:41] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:24:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:25:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:49] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:27:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:28:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:29:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:30:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:33:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage Accuracy: 0.8691342380544486,\n",
      "\tAverage F1 Score: 0.8689520979108059,\n",
      "\tAverage Precision: 0.8716598475020902,\n",
      "\tAverage Recall: 0.8690021134516959\n",
      "\n",
      "Loading features for language model: bert-cased...\n",
      "bert-cased NLP\n",
      "Cross-validating Light GBM...\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43842, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368794\n",
      "[LightGBM] [Info] Start training from score -1.391738\n",
      "[LightGBM] [Info] Start training from score -1.372747\n",
      "[LightGBM] [Info] Start training from score -1.412500\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372769\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391852\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368817\n",
      "[LightGBM] [Info] Start training from score -1.391852\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 43843, number of used features: 768\n",
      "[LightGBM] [Info] Start training from score -1.368907\n",
      "[LightGBM] [Info] Start training from score -1.391761\n",
      "[LightGBM] [Info] Start training from score -1.372679\n",
      "[LightGBM] [Info] Start training from score -1.412430\n",
      "Light GBM cross-validation complete. \n",
      "\tAverage Accuracy: 0.8886565213375363,\n",
      "\tAverage F1 Score: 0.8886027013657797,\n",
      "\tAverage Precision: 0.8904850606211931,\n",
      "\tAverage Recall: 0.8885823930090601\n",
      "\n",
      "Cross-validating K-Nearest Neighbors...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage Accuracy: 0.8784949142726347,\n",
      "\tAverage F1 Score: 0.8784494815708468,\n",
      "\tAverage Precision: 0.8806651616845336,\n",
      "\tAverage Recall: 0.878429935766501\n",
      "\n",
      "Cross-validating Random Forest...\n",
      "Random Forest cross-validation complete. \n",
      "\tAverage Accuracy: 0.8797678040910331,\n",
      "\tAverage F1 Score: 0.8798146438678467,\n",
      "\tAverage Precision: 0.8832868465753909,\n",
      "\tAverage Recall: 0.8795409161121913\n",
      "\n",
      "Cross-validating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:39:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:41:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:42:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:43:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:44:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:45:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:46:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage Accuracy: 0.8892106368949436,\n",
      "\tAverage F1 Score: 0.889293889844318,\n",
      "\tAverage Precision: 0.890529121793658,\n",
      "\tAverage Recall: 0.88916256954726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def cross_validate_classification(model, X, y, kf=None):\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123) if kf is None else kf\n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "        model_clone = clone(model)\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit the model\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        # Calculate accuracy\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        # Calculate F1 score\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        # Calculate precision\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        # Calculate recall\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    # Calculate average scores\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    return average_accuracy, average_f1, average_precision, average_recall\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models = {\n",
    "    \"Light GBM\": lgb.LGBMClassifier(n_estimators=100, n_jobs=45),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_jobs=45),\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=2000, solver='lbfgs', multi_class='auto'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, n_jobs=45),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \n",
    "#     \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, n_jobs=45)\n",
    "}\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_pca(features, n_components):\n",
    "    \"\"\"\n",
    "    Perform Principal Component Analysis (PCA) on the provided features.\n",
    "\n",
    "    Args:\n",
    "    features: numpy array of features\n",
    "    n_components: number of principal components to retain\n",
    "\n",
    "    Returns:\n",
    "    A numpy array where each row is the original feature vector projected onto the top `n_components` principal components.\n",
    "    \"\"\"\n",
    "    print(\"Starting PCA...\")\n",
    "    print(features.shape)\n",
    "    # Initialize PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    # Fit and transform the data\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    print(\"PCA complete.\")\n",
    "    print(f\"Reduced data shape: {reduced_features.shape}\")\n",
    "\n",
    "    return reduced_features\n",
    "\n",
    "#'mt5', 'mt5-large'\n",
    "\n",
    "\n",
    "model_names = ['bert', 'bert-large', 'roberta', 'roberta-large', 'xlnet', 'xlnet-large','albert','albert-large']#[]\n",
    "\n",
    "model_names = ['distilroberta','bert-cased']\n",
    "\n",
    "feature_sets = ['NLP']\n",
    "\n",
    "\n",
    "BASE = dt.drop(['Severity'],axis=1).values\n",
    "\n",
    "SX = dt.Severity.values\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "reportonce=False\n",
    "\n",
    "\n",
    "for language_model in model_names:\n",
    "    print(f\"Loading features for language model: {language_model}...\")\n",
    "    NLP = load_features(language_model)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    NLP = scaler.fit_transform(NLP)\n",
    "#     quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "#     NLP = quantile_transformer.fit_transform(NLP)\n",
    "    \n",
    "#     NLP = perform_pca(NLP, 32)\n",
    "#     from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "    \n",
    "    XES=None\n",
    "    \n",
    "    \n",
    "    for feature_set in feature_sets:\n",
    "        if feature_set == 'NLP':\n",
    "            XES = NLP\n",
    "            \n",
    "        elif feature_set == 'report':\n",
    "            \n",
    "            if reportonce:\n",
    "                continue\n",
    "                \n",
    "            XES = BASE\n",
    "            reportonce=True\n",
    "        elif feature_set == 'report+NLP':\n",
    "            XES = np.concatenate([BASE,NLP],axis=1)\n",
    "            \n",
    "        print(language_model, feature_set)\n",
    "        \n",
    "#         quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "#         XES = quantile_transformer.fit_transform(XES)\n",
    "        \n",
    "        \n",
    "#         scaler = StandardScaler()\n",
    "#         XES = scaler.fit_transform(XES)\n",
    "\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Cross-validating {model_name}...\")\n",
    "            average_accuracy, average_f1, average_precision, average_recall = cross_validate_classification(model, XES, SX-1)\n",
    "            results.append([model_name, language_model, feature_set, average_accuracy, average_f1, average_precision, average_recall])\n",
    "            print(f\"{model_name} cross-validation complete. \\n\\tAverage Accuracy: {average_accuracy},\\n\\tAverage F1 Score: {average_f1},\\n\\tAverage Precision: {average_precision},\\n\\tAverage Recall: {average_recall}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aef80521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average F1 Score</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>distilroberta</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>distilroberta</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>distilroberta</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>distilroberta</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>bert-cased</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>bert-cased</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bert-cased</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>bert-cased</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Language Model Features  Average Accuracy  \\\n",
       "0            Light GBM  distilroberta      NLP             0.868   \n",
       "1  K-Nearest Neighbors  distilroberta      NLP             0.848   \n",
       "2        Random Forest  distilroberta      NLP             0.857   \n",
       "3              XGBoost  distilroberta      NLP             0.869   \n",
       "4            Light GBM     bert-cased      NLP             0.889   \n",
       "5  K-Nearest Neighbors     bert-cased      NLP             0.878   \n",
       "6        Random Forest     bert-cased      NLP             0.880   \n",
       "7              XGBoost     bert-cased      NLP             0.889   \n",
       "\n",
       "   Average F1 Score  Average Precision  Average Recall  \n",
       "0             0.867              0.871           0.867  \n",
       "1             0.848              0.853           0.848  \n",
       "2             0.857              0.862           0.857  \n",
       "3             0.869              0.872           0.869  \n",
       "4             0.889              0.890           0.889  \n",
       "5             0.878              0.881           0.878  \n",
       "6             0.880              0.883           0.880  \n",
       "7             0.889              0.891           0.889  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model', 'Language Model','Features','Average Accuracy', 'Average F1 Score', 'Average Precision', 'Average Recall']).round(3)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5424d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b318c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[results_df['Features'] == 'report', 'Language Model'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dddc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_average(df):\n",
    "#     df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "#     # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "#     df_avg = df.groupby(['Language Model','Features', 'Model'], as_index=False).mean()\n",
    "    \n",
    "#     return df_avg\n",
    "# results_df = calculate_average(results_df)\n",
    "results_df.to_csv('DESC-results-LLM-flat-even-severity-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68910f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceff811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c3296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af285165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ff40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Language Model', 'Features', 'Model', 'Average RMSE', 'Average MAPE']).round(2)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30b1c289",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "5 columns passed, passed data had 7 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/ENV/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    688\u001b[0m             raise AssertionError(\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;34mf\"{len(content)} columns\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 5 columns passed, passed data had 7 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2c98cab2de77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Language Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Average RMSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Average MAPE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Features'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'report'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Language Model'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENV/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m~/ENV/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 5 columns passed, passed data had 7 columns"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Language Model', 'Features', 'Model', 'Average RMSE', 'Average MAPE']).round(2)\n",
    "print(results_df)\n",
    "\n",
    "results_df.loc[results_df['Features'] == 'report', 'Language Model'] = '-'\n",
    "\n",
    "results_df.to_csv('results-LLM-32-even-duration-final-BL.csv')\n",
    "\n",
    "def calculate_average(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "    df_avg = df.groupby(['Language Model','Features', 'Model'], as_index=False).mean().round(2)\n",
    "    \n",
    "    return df_avg\n",
    "results_df = calculate_average(results_df)\n",
    "results_df.to_csv('results-LLM-32-even-duration-final-BL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f439f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2224ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cac30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcd149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54645adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3b0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be013d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545474b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f2d9d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I assume 'dt' is your DataFrame and 'BASE' and 'SX' are numpy arrays\n",
    "# BASE = dt.drop(['Crash_Severity'], axis=1).values\n",
    "# SX = dt.Crash_Severity.values\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(dt.drop(['Crash_Severity'],axis=1), SX)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = dt.drop(['Crash_Severity'], axis=1).columns\n",
    "\n",
    "# Sort feature importances in descending order and get the indices\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(BASE.shape[1]), feature_importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(BASE.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553d51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc337a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead42e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72574d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d8693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e403e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fe05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfe470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e51951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d674af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37121acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e30e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=50, n_jobs=1) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.expm1(y_true), np.expm1(y_pred)  # Apply expm1 before calculating the metrics\n",
    "    return np.mean(np.where(y_true != 0, np.abs((y_true - y_pred) / y_true), 0)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0b3ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# def preprocess_and_encode(df):\n",
    "#     # Create a copy of the dataframe\n",
    "#     df_encoded = df.copy()\n",
    "\n",
    "#     # Fill NaN values with -1\n",
    "#     df_encoded.fillna(-1, inplace=True)\n",
    "\n",
    "#     # Label encoding for categorical columns and numerical columns with 30 or fewer unique values\n",
    "#     label_encoders = {}\n",
    "#     for col in df_encoded.select_dtypes(include=['object']).columns:\n",
    "#         le = LabelEncoder()\n",
    "#         df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "#         label_encoders[col] = le\n",
    "\n",
    "#     for col in df_encoded.select_dtypes(include=['int64']).columns:\n",
    "#         if df_encoded[col].nunique() <= 30:\n",
    "#             le = LabelEncoder()\n",
    "#             df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "#             label_encoders[col] = le\n",
    "\n",
    "#     # Convert boolean columns to int\n",
    "#     for col in df_encoded.select_dtypes(include=['bool']).columns:\n",
    "#         df_encoded[col] = df_encoded[col].astype(int)\n",
    "        \n",
    "#     return df_encoded #, label_encoders\n",
    "\n",
    "\n",
    "# BASE = preprocess_and_encode(dt.drop(['Duration','Severity','FullText','Description'],axis=1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceebe95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c698876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBRegressor(n_estimators=50, n_jobs=1) \n",
    "# model.fit(BASE,DX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e96ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validate(model, X, y, kf):\n",
    "#     rmse_scores = []\n",
    "#     mape_scores = []\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "#         model_clone = clone(model)\n",
    "#         # Split the data\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "#         # Fit the model\n",
    "#         model_clone.fit(X_train, y_train)\n",
    "#         # Make predictions\n",
    "#         y_pred = model_clone.predict(X_test)\n",
    "#         # Calculate RMSE\n",
    "#         mse_score = np.mean((np.expm1(y_test) - np.expm1(y_pred)) ** 2)\n",
    "#         rmse_score = np.sqrt(mse_score)\n",
    "#         rmse_scores.append(rmse_score)\n",
    "#         # Calculate MAPE\n",
    "#         mape_score = mean_absolute_percentage_error(y_test, y_pred)\n",
    "#         mape_scores.append(mape_score)\n",
    "#     # Calculate average scores\n",
    "#     average_rmse = np.mean(rmse_scores)\n",
    "#     average_mape = np.mean(mape_scores)\n",
    "#     return average_rmse, average_mape\n",
    "\n",
    "\n",
    "# cross_validate(model, BASE, np.log1p(DX), kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebffb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "# BASE = quantile_transformer.fit_transform(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934b5d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for language model: bert-large...\n",
      "Starting PCA...\n",
      "(48714, 1024)\n",
      "PCA complete.\n",
      "Reduced data shape: (48714, 32)\n",
      "bert-large report\n",
      "Cross-validating Linear Regression with report features from bert-large...\n",
      "Linear Regression cross-validation complete. \n",
      "\tAverage RMSE: 99.89293636694904,\n",
      "\tAverage MAPE: 72.2036299456897\n",
      "\n",
      "Cross-validating K-Nearest Neighbors with report features from bert-large...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage RMSE: 80.74113198432069,\n",
      "\tAverage MAPE: 55.55598514954463\n",
      "\n",
      "Cross-validating ElasticNet with report features from bert-large...\n",
      "ElasticNet cross-validation complete. \n",
      "\tAverage RMSE: 102.65388986812445,\n",
      "\tAverage MAPE: 73.61024500620962\n",
      "\n",
      "Cross-validating DecisionTree with report features from bert-large...\n",
      "DecisionTree cross-validation complete. \n",
      "\tAverage RMSE: 79.95855623011502,\n",
      "\tAverage MAPE: 55.90011444501965\n",
      "\n",
      "Cross-validating RandomForest with report features from bert-large...\n",
      "RandomForest cross-validation complete. \n",
      "\tAverage RMSE: 58.919060891833865,\n",
      "\tAverage MAPE: 36.43038587724071\n",
      "\n",
      "Cross-validating XGBoost with report features from bert-large...\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage RMSE: 60.94378780973936,\n",
      "\tAverage MAPE: 37.95047554393552\n",
      "\n",
      "bert-large NLP\n",
      "Cross-validating Linear Regression with NLP features from bert-large...\n",
      "Linear Regression cross-validation complete. \n",
      "\tAverage RMSE: 99.70580237360745,\n",
      "\tAverage MAPE: 71.70857364234269\n",
      "\n",
      "Cross-validating K-Nearest Neighbors with NLP features from bert-large...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage RMSE: 91.21978395440512,\n",
      "\tAverage MAPE: 62.14481491937003\n",
      "\n",
      "Cross-validating ElasticNet with NLP features from bert-large...\n",
      "ElasticNet cross-validation complete. \n",
      "\tAverage RMSE: 114.07505313665709,\n",
      "\tAverage MAPE: 78.35561332217992\n",
      "\n",
      "Cross-validating DecisionTree with NLP features from bert-large...\n",
      "DecisionTree cross-validation complete. \n",
      "\tAverage RMSE: 122.62141543889281,\n",
      "\tAverage MAPE: 108.91935775677989\n",
      "\n",
      "Cross-validating RandomForest with NLP features from bert-large...\n",
      "RandomForest cross-validation complete. \n",
      "\tAverage RMSE: 93.77247690333222,\n",
      "\tAverage MAPE: 63.34966407962985\n",
      "\n",
      "Cross-validating XGBoost with NLP features from bert-large...\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage RMSE: 93.57199877359469,\n",
      "\tAverage MAPE: 65.4208978149272\n",
      "\n",
      "bert-large report+NLP\n",
      "Cross-validating Linear Regression with report+NLP features from bert-large...\n",
      "Linear Regression cross-validation complete. \n",
      "\tAverage RMSE: 94.08319149565722,\n",
      "\tAverage MAPE: 66.51293706044805\n",
      "\n",
      "Cross-validating K-Nearest Neighbors with report+NLP features from bert-large...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage RMSE: 80.74113198432069,\n",
      "\tAverage MAPE: 55.55598514954463\n",
      "\n",
      "Cross-validating ElasticNet with report+NLP features from bert-large...\n",
      "ElasticNet cross-validation complete. \n",
      "\tAverage RMSE: 102.65388986812445,\n",
      "\tAverage MAPE: 73.61024500620962\n",
      "\n",
      "Cross-validating DecisionTree with report+NLP features from bert-large...\n",
      "DecisionTree cross-validation complete. \n",
      "\tAverage RMSE: 80.66780200430466,\n",
      "\tAverage MAPE: 56.03109638812614\n",
      "\n",
      "Cross-validating RandomForest with report+NLP features from bert-large...\n",
      "RandomForest cross-validation complete. \n",
      "\tAverage RMSE: 59.058971580712026,\n",
      "\tAverage MAPE: 35.46188418758045\n",
      "\n",
      "Cross-validating XGBoost with report+NLP features from bert-large...\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage RMSE: 61.68100274338151,\n",
      "\tAverage MAPE: 37.34189586340568\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfe5cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language Model    Features                Model  Average RMSE  Average MAPE\n",
      "0      bert-large      report    Linear Regression         99.89         72.20\n",
      "1      bert-large      report  K-Nearest Neighbors         80.74         55.56\n",
      "2      bert-large      report           ElasticNet        102.65         73.61\n",
      "3      bert-large      report         DecisionTree         79.96         55.90\n",
      "4      bert-large      report         RandomForest         58.92         36.43\n",
      "5      bert-large      report              XGBoost         60.94         37.95\n",
      "6      bert-large         NLP    Linear Regression         99.71         71.71\n",
      "7      bert-large         NLP  K-Nearest Neighbors         91.22         62.14\n",
      "8      bert-large         NLP           ElasticNet        114.08         78.36\n",
      "9      bert-large         NLP         DecisionTree        122.62        108.92\n",
      "10     bert-large         NLP         RandomForest         93.77         63.35\n",
      "11     bert-large         NLP              XGBoost         93.57         65.42\n",
      "12     bert-large  report+NLP    Linear Regression         94.08         66.51\n",
      "13     bert-large  report+NLP  K-Nearest Neighbors         80.74         55.56\n",
      "14     bert-large  report+NLP           ElasticNet        102.65         73.61\n",
      "15     bert-large  report+NLP         DecisionTree         80.67         56.03\n",
      "16     bert-large  report+NLP         RandomForest         59.06         35.46\n",
      "17     bert-large  report+NLP              XGBoost         61.68         37.34\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0e6e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2474df88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad741b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2eee94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea8da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3f1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6e2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f125784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432c7179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910ebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5483a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# BASE = scaler.fit_transform(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96c35fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import QuantileTransformer\n",
    "# quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "    \n",
    "    \n",
    "# BASE = quantile_transformer.fit_transform(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c437db",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    NLP = scaler.fit_transform(NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4aea58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2bc4380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for language model: bert-large...\n",
      "Starting PCA...\n",
      "(48714, 1024)\n",
      "PCA complete.\n",
      "Reduced data shape: (48714, 32)\n",
      "bert-large report\n",
      "Cross-validating K-Nearest Neighbors...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage Accuracy: 0.6696844305579855,\n",
      "\tAverage F1 Score: 0.663122557168384,\n",
      "\tAverage Precision: 0.6643540525477458,\n",
      "\tAverage Recall: 0.6677183168590339\n",
      "\n",
      "Cross-validating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression cross-validation complete. \n",
      "\tAverage Accuracy: 0.6089828621117778,\n",
      "\tAverage F1 Score: 0.5935247725688361,\n",
      "\tAverage Precision: 0.5977611040151338,\n",
      "\tAverage Recall: 0.6080896154455994\n",
      "\n",
      "Cross-validating Random Forest...\n",
      "Random Forest cross-validation complete. \n",
      "\tAverage Accuracy: 0.8117379288770138,\n",
      "\tAverage F1 Score: 0.8082336769432048,\n",
      "\tAverage Precision: 0.8098286300820838,\n",
      "\tAverage Recall: 0.8108928901044129\n",
      "\n",
      "Cross-validating Decision Tree...\n",
      "Decision Tree cross-validation complete. \n",
      "\tAverage Accuracy: 0.7412447719302504,\n",
      "\tAverage F1 Score: 0.7401001413335596,\n",
      "\tAverage Precision: 0.7401227877014839,\n",
      "\tAverage Recall: 0.7401574762255465\n",
      "\n",
      "Cross-validating XGBoost...\n",
      "[13:23:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:23:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:24:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage Accuracy: 0.8188407632855421,\n",
      "\tAverage F1 Score: 0.8163386482511636,\n",
      "\tAverage Precision: 0.8162986824139707,\n",
      "\tAverage Recall: 0.8180122561811991\n",
      "\n",
      "bert-large NLP\n",
      "Cross-validating K-Nearest Neighbors...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage Accuracy: 0.8509052057028648,\n",
      "\tAverage F1 Score: 0.8495456935044998,\n",
      "\tAverage Precision: 0.8517646021012872,\n",
      "\tAverage Recall: 0.850343527394881\n",
      "\n",
      "Cross-validating Logistic Regression...\n",
      "Logistic Regression cross-validation complete. \n",
      "\tAverage Accuracy: 0.8281810868182357,\n",
      "\tAverage F1 Score: 0.8263087262198656,\n",
      "\tAverage Precision: 0.8264441228972871,\n",
      "\tAverage Recall: 0.8277180310725207\n",
      "\n",
      "Cross-validating Random Forest...\n",
      "Random Forest cross-validation complete. \n",
      "\tAverage Accuracy: 0.837315898793132,\n",
      "\tAverage F1 Score: 0.8361124507286009,\n",
      "\tAverage Precision: 0.8359534529563808,\n",
      "\tAverage Recall: 0.8369847009039642\n",
      "\n",
      "Cross-validating Decision Tree...\n",
      "Decision Tree cross-validation complete. \n",
      "\tAverage Accuracy: 0.7192387910218279,\n",
      "\tAverage F1 Score: 0.7188892496217152,\n",
      "\tAverage Precision: 0.7190638386061304,\n",
      "\tAverage Recall: 0.7188162737607816\n",
      "\n",
      "Cross-validating XGBoost...\n",
      "[13:26:06] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:10] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage Accuracy: 0.8519728873575355,\n",
      "\tAverage F1 Score: 0.851016610084328,\n",
      "\tAverage Precision: 0.8510596459690193,\n",
      "\tAverage Recall: 0.8516769988074339\n",
      "\n",
      "bert-large report+NLP\n",
      "Cross-validating K-Nearest Neighbors...\n",
      "K-Nearest Neighbors cross-validation complete. \n",
      "\tAverage Accuracy: 0.6696844305579855,\n",
      "\tAverage F1 Score: 0.663122557168384,\n",
      "\tAverage Precision: 0.6643540525477458,\n",
      "\tAverage Recall: 0.6677183168590339\n",
      "\n",
      "Cross-validating Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression cross-validation complete. \n",
      "\tAverage Accuracy: 0.6093935144123981,\n",
      "\tAverage F1 Score: 0.5948169860386922,\n",
      "\tAverage Precision: 0.5984116354128882,\n",
      "\tAverage Recall: 0.6085679457508283\n",
      "\n",
      "Cross-validating Random Forest...\n",
      "Random Forest cross-validation complete. \n",
      "\tAverage Accuracy: 0.875169449801597,\n",
      "\tAverage F1 Score: 0.8738467855907736,\n",
      "\tAverage Precision: 0.8748978506578655,\n",
      "\tAverage Recall: 0.8746370391900868\n",
      "\n",
      "Cross-validating Decision Tree...\n",
      "Decision Tree cross-validation complete. \n",
      "\tAverage Accuracy: 0.7991748397657933,\n",
      "\tAverage F1 Score: 0.7985536221847223,\n",
      "\tAverage Precision: 0.798686420234453,\n",
      "\tAverage Recall: 0.7985762748021037\n",
      "\n",
      "Cross-validating XGBoost...\n",
      "[13:30:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:30:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:08] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost cross-validation complete. \n",
      "\tAverage Accuracy: 0.890134454981208,\n",
      "\tAverage F1 Score: 0.8893200796036116,\n",
      "\tAverage Precision: 0.8897662191948772,\n",
      "\tAverage Recall: 0.8897179489643507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def cross_validate_classification(model, X, y, kf=None):\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123) if kf is None else kf\n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "        model_clone = clone(model)\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit the model\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        # Calculate accuracy\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        # Calculate F1 score\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        # Calculate precision\n",
    "        precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        # Calculate recall\n",
    "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    # Calculate average scores\n",
    "    average_accuracy = np.mean(accuracy_scores)\n",
    "    average_f1 = np.mean(f1_scores)\n",
    "    average_precision = np.mean(precision_scores)\n",
    "    average_recall = np.mean(recall_scores)\n",
    "    return average_accuracy, average_f1, average_precision, average_recall\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# models = {\n",
    "#     \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "#     \"Random Forest\": RandomForestClassifier(n_estimators=50, n_jobs=1),\n",
    "# #     \"Support Vector Classifier\": SVC(),\n",
    "#     \"XGBoost\": XGBClassifier(n_estimators=50, n_jobs=1)\n",
    "# }\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models = {\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_jobs=40),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto'),\n",
    "    \n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \n",
    "#     \"Multinomial Naive Bayes\": MultinomialNB(),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=50, n_jobs=40)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_names = ['bert-large']#['bert', 'gpt2', 'roberta', 'mt5', 'mt5-large', 'xlnet', 'xlnet-large']\n",
    "\n",
    "feature_sets = ['report','NLP','report+NLP']\n",
    "\n",
    "\n",
    "\n",
    "SX = dt.Severity.values\n",
    "DX = dt.Duration.values\n",
    "\n",
    "results = []\n",
    "\n",
    "for language_model in model_names:\n",
    "    print(f\"Loading features for language model: {language_model}...\")\n",
    "    FX = load_features(language_model)\n",
    "    NLP = perform_pca(FX, 32)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    NLP = scaler.fit_transform(NLP)\n",
    "#     from sklearn.preprocessing import QuantileTransformer\n",
    "#     quantile_transformer = QuantileTransformer(output_distribution='uniform')\n",
    "#     NLP = quantile_transformer.fit_transform(NLP)\n",
    "\n",
    "    \n",
    "    XES=None\n",
    "    \n",
    "    for feature_set in feature_sets:\n",
    "        if feature_set == 'NLP':\n",
    "            XES = NLP\n",
    "        elif feature_set == 'report':\n",
    "            XES = BASE\n",
    "        elif feature_set == 'report+NLP':\n",
    "            XES = np.concatenate([BASE,NLP],axis=1)\n",
    "            \n",
    "        print(language_model, feature_set)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Cross-validating {model_name}...\")\n",
    "            average_accuracy, average_f1, average_precision, average_recall = cross_validate_classification(model, XES, SX-1)\n",
    "            results.append([model_name, language_model, feature_set, average_accuracy, average_f1, average_precision, average_recall])\n",
    "            print(f\"{model_name} cross-validation complete. \\n\\tAverage Accuracy: {average_accuracy},\\n\\tAverage F1 Score: {average_f1},\\n\\tAverage Precision: {average_precision},\\n\\tAverage Recall: {average_recall}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a37c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d074a977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Average Accuracy</th>\n",
       "      <th>Average F1 Score</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report+NLP</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report+NLP</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report+NLP</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report+NLP</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>bert-large</td>\n",
       "      <td>report+NLP</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Language Model    Features  Average Accuracy  \\\n",
       "0   K-Nearest Neighbors     bert-large      report             0.670   \n",
       "1   Logistic Regression     bert-large      report             0.609   \n",
       "2         Random Forest     bert-large      report             0.812   \n",
       "3         Decision Tree     bert-large      report             0.741   \n",
       "4               XGBoost     bert-large      report             0.819   \n",
       "5   K-Nearest Neighbors     bert-large         NLP             0.851   \n",
       "6   Logistic Regression     bert-large         NLP             0.828   \n",
       "7         Random Forest     bert-large         NLP             0.837   \n",
       "8         Decision Tree     bert-large         NLP             0.719   \n",
       "9               XGBoost     bert-large         NLP             0.852   \n",
       "10  K-Nearest Neighbors     bert-large  report+NLP             0.670   \n",
       "11  Logistic Regression     bert-large  report+NLP             0.609   \n",
       "12        Random Forest     bert-large  report+NLP             0.875   \n",
       "13        Decision Tree     bert-large  report+NLP             0.799   \n",
       "14              XGBoost     bert-large  report+NLP             0.890   \n",
       "\n",
       "    Average F1 Score  Average Precision  Average Recall  \n",
       "0              0.663              0.664           0.668  \n",
       "1              0.594              0.598           0.608  \n",
       "2              0.808              0.810           0.811  \n",
       "3              0.740              0.740           0.740  \n",
       "4              0.816              0.816           0.818  \n",
       "5              0.850              0.852           0.850  \n",
       "6              0.826              0.826           0.828  \n",
       "7              0.836              0.836           0.837  \n",
       "8              0.719              0.719           0.719  \n",
       "9              0.851              0.851           0.852  \n",
       "10             0.663              0.664           0.668  \n",
       "11             0.595              0.598           0.609  \n",
       "12             0.874              0.875           0.875  \n",
       "13             0.799              0.799           0.799  \n",
       "14             0.889              0.890           0.890  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e3b3964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96d681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Model', 'Language Model','Features','Average Accuracy', 'Average F1 Score', 'Average Precision', 'Average Recall']).round(3)\n",
    "results_df\n",
    "\n",
    "\n",
    "results_df.loc[results_df['Features'] == 'report', 'Language Model'] = '-'\n",
    "\n",
    "results_df.to_csv('results-LLM-32-even-severity-final-BL.csv')\n",
    "\n",
    "def calculate_average(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "    df_avg = df.groupby(['Language Model','Features', 'Model'], as_index=False).mean()\n",
    "    \n",
    "    return df_avg\n",
    "results_df = calculate_average(results_df)\n",
    "results_df.to_csv('results-LLM-32-even-severity-final-BL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07f720e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48714, 75)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XES.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa6e8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = pd.read_csv('results-LLM-32-even-severity-final-0.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb39f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.loc[xt['Feature Set'] == 'report', 'Language Model'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13b68697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "    df_avg = df.groupby(['Language Model','Feature Set', 'Model'], as_index=False).mean().round(3)\n",
    "    \n",
    "    return df_avg\n",
    "xt = calculate_average(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc1bd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.to_csv('results-LLM-32-even-severity-final-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bc163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c23a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1349da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29021b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34512046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b202d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=50, n_jobs=1) \n",
    "}\n",
    "\n",
    "# List of language models\n",
    "language_models = ['roberta', 'bert', 'gpt2', 'mt5','xlnet']\n",
    "\n",
    "# language_models = ['xlnet']\n",
    "\n",
    "# Feature sets\n",
    "feature_sets = ['VX', 'TX', 'VX+TX']\n",
    "\n",
    "feature_sets = ['VX', 'VX+TX']\n",
    "\n",
    "# Function to compute the Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "\n",
    "# Define KFold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate(model, X, y, kf):\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "        model_clone = clone(model)\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit the model\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        # Calculate RMSE\n",
    "        mse_score = np.mean((np.expm1(y_test) - np.expm1(y_pred)) ** 2)\n",
    "        rmse_score = np.sqrt(mse_score)\n",
    "        rmse_scores.append(rmse_score)\n",
    "        # Calculate MAPE\n",
    "        mape_score = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_scores.append(mape_score)\n",
    "    # Calculate average scores\n",
    "    average_rmse = np.mean(rmse_scores)\n",
    "    average_mape = np.mean(mape_scores)\n",
    "    return average_rmse, average_mape\n",
    "\n",
    "\n",
    "results = []\n",
    "y = np.log1p(DX)\n",
    "# Calculate cross-validation score for each model\n",
    "for language_model in language_models:\n",
    "    print(f\"Loading features for language model: {language_model}...\")\n",
    "    FX = load_features(language_model)[filtered]\n",
    "    VX = perform_pca(FX, 32)\n",
    "    for feature_set in feature_sets:\n",
    "        if feature_set == 'VX':\n",
    "            X = VX\n",
    "        elif feature_set == 'TX':\n",
    "            X = TX\n",
    "        elif feature_set == 'VX+TX':\n",
    "            X = np.concatenate([VX,TX],axis=1)\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Cross-validating {model_name} with {feature_set} features from {language_model}...\")\n",
    "            average_rmse, average_mape = cross_validate(model, XES, YES, kf)\n",
    "            results.append([language_model, feature_set, model_name, average_rmse, average_mape])\n",
    "            print(f\"{model_name} cross-validation complete. Average RMSE: {average_rmse}, Average MAPE: {average_mape}\\n\")\n",
    "\n",
    "# Convert results to DataFrame for a nice table display\n",
    "results_df = pd.DataFrame(results, columns=['Language Model', 'Features', 'Model', 'Average RMSE', 'Average MAPE']).round(2)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a50d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d057eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a548fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c586a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd67b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess_and_encode(df):\n",
    "    # Create a copy of the dataframe\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    # Fill NaN values with -1\n",
    "    df_encoded.fillna(-1, inplace=True)\n",
    "\n",
    "    # Label encoding for categorical columns\n",
    "    label_encoders = {}\n",
    "    for col in df_encoded.select_dtypes(include=['object', 'int64']).columns:\n",
    "        le = LabelEncoder()\n",
    "        # Convert everything to string before encoding\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Convert boolean columns to int\n",
    "    for col in df_encoded.select_dtypes(include=['bool']).columns:\n",
    "        df_encoded[col] = df_encoded[col].astype(int)\n",
    "        \n",
    "    return df_encoded #, label_encoders\n",
    "\n",
    "TX = preprocess_and_encode(dt.drop(['Duration','Severity','FullText','Description'],axis=1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f7d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48714, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SX = dt.Severity.values\n",
    "DX = dt.Duration.values\n",
    "FX = load_features('bert')\n",
    "FX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9094359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48714,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e4780aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered = DX<720\n",
    "# FX=FX[filtered]\n",
    "# SX=SX[filtered]\n",
    "# TX=TX[filtered]\n",
    "# DX=DX[filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a907fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "\n",
    "# Define the quantiles\n",
    "quantiles = np.quantile(DX, [0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "# Set the style\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Create the histogram\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.histplot(DX, bins=50, kde=True, color='blue')\n",
    "\n",
    "# Add quantile ticks and labels\n",
    "# for q in quantiles:\n",
    "#     plt.axvline(x=q, color='red', linestyle='--', alpha=0.8)\n",
    "#     plt.text(q, 0, f'{q:.0f}', rotation=45, color='red', verticalalignment='bottom')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Histogram of Traffic Accident Duration')\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(0,400)\n",
    "# Save as PDF\n",
    "plt.tight_layout()\n",
    "plt.savefig('traffic_accident_histogram.pdf', format='pdf')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f8223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7dbd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Usage:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b747e10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(SX,bins=10)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e26278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde3ee79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48714, 43)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c1522e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([360.,  34.,  22.,  30.,  60.,  30.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8333707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61af4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a306f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "803a23cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (48714, 32)\n",
      "Cross-validating Linear Regression...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9743 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e5adb6e483fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cross-validating {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0maverage_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_mape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_mape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_name} cross-validation complete. Average RMSE: {average_rmse}, Average MAPE: {average_mape}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-e5adb6e483fb>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(model, X, y, kf)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Split the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9743 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "#     \"SGD\": SGDRegressor(loss='huber',max_iter=1000),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(max_depth=8),\n",
    "#     \"LightGBM\": LGBMRegressor(),\n",
    "#     \"Random Forest\": RandomForestRegressor(),\n",
    "#     \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=50,n_jobs=1) \n",
    "}\n",
    "\n",
    "FX = load_features('roberta') #'bert','gpt2'\n",
    "VX = perform_pca(FX,32)\n",
    "\n",
    "# Prepare data (X, y)\n",
    "XES = np.concatenate([VX,TX],axis=1) #VX only, TX only, VX+TX\n",
    "YES = np.log1p(DX)  # Apply log1p transformation to the target\n",
    "\n",
    "# Function to compute the Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.expm1(y_true), np.expm1(y_pred)  # Apply expm1 before calculating the metrics\n",
    "    return np.mean(np.where(y_true != 0, np.abs((y_true - y_pred) / y_true), 0)) * 100\n",
    "\n",
    "# For storing results\n",
    "results = []\n",
    "\n",
    "# Define KFold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate(model, X, y, kf):\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "        model_clone = clone(model)\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fit the model\n",
    "        print(f\"Fitting {model.__class__.__name__}...\")\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        print(\"Making predictions...\")\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        \n",
    "        y_pred = np.clip(y_pred, 0, np.log1p(720))\n",
    "        # Calculate RMSE\n",
    "        mse_score = np.mean((np.expm1(y_test) - np.expm1(y_pred)) ** 2)\n",
    "        rmse_score = np.sqrt(mse_score)\n",
    "        rmse_scores.append(rmse_score)\n",
    "        \n",
    "        # Calculate MAPE\n",
    "        mape_score = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_scores.append(mape_score)\n",
    "    \n",
    "    # Calculate average scores\n",
    "    average_rmse = np.mean(rmse_scores)\n",
    "    average_mape = np.mean(mape_scores)\n",
    "    \n",
    "    return average_rmse, average_mape\n",
    "\n",
    "# Calculate cross-validation score for each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Cross-validating {model_name}...\")\n",
    "    average_rmse, average_mape = cross_validate(model, XES, YES, kf)\n",
    "    results.append([model_name, average_rmse, average_mape])\n",
    "    print(f\"{model_name} cross-validation complete. Average RMSE: {average_rmse}, Average MAPE: {average_mape}\\n\")\n",
    "\n",
    "# Convert results to DataFrame for a nice table display\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Average RMSE', 'Average MAPE']).round(2)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67ec5634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features for language model: roberta...\n",
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (47915, 32)\n",
      "Cross-validating Linear Regression with VX features from roberta...\n",
      "Linear Regression cross-validation complete. Average RMSE: 104.8884906958792, Average MAPE: 70.70305116168046\n",
      "\n",
      "Cross-validating ElasticNet with VX features from roberta...\n",
      "ElasticNet cross-validation complete. Average RMSE: 118.48861009170032, Average MAPE: 79.36174039553539\n",
      "\n",
      "Cross-validating DecisionTree with VX features from roberta...\n",
      "DecisionTree cross-validation complete. Average RMSE: 130.30401799298437, Average MAPE: 111.17382413138598\n",
      "\n",
      "Cross-validating XGBoost with VX features from roberta...\n",
      "XGBoost cross-validation complete. Average RMSE: 98.44843735025587, Average MAPE: 68.22698880664606\n",
      "\n",
      "Cross-validating Linear Regression with VX+TX features from roberta...\n",
      "Linear Regression cross-validation complete. Average RMSE: 101.31657877888654, Average MAPE: 65.5828456851471\n",
      "\n",
      "Cross-validating ElasticNet with VX+TX features from roberta...\n",
      "ElasticNet cross-validation complete. Average RMSE: 105.53332099580284, Average MAPE: 69.01677358761617\n",
      "\n",
      "Cross-validating DecisionTree with VX+TX features from roberta...\n",
      "DecisionTree cross-validation complete. Average RMSE: 92.79982937908485, Average MAPE: 64.03719103805489\n",
      "\n",
      "Cross-validating XGBoost with VX+TX features from roberta...\n",
      "XGBoost cross-validation complete. Average RMSE: 71.07289532030035, Average MAPE: 42.58759830079221\n",
      "\n",
      "Loading features for language model: bert...\n",
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (47915, 32)\n",
      "Cross-validating Linear Regression with VX features from bert...\n",
      "Linear Regression cross-validation complete. Average RMSE: 104.44482066711639, Average MAPE: 68.8502969230688\n",
      "\n",
      "Cross-validating ElasticNet with VX features from bert...\n",
      "ElasticNet cross-validation complete. Average RMSE: 118.48861009170032, Average MAPE: 79.36174039553539\n",
      "\n",
      "Cross-validating DecisionTree with VX features from bert...\n",
      "DecisionTree cross-validation complete. Average RMSE: 125.92065010138715, Average MAPE: 104.48777288599976\n",
      "\n",
      "Cross-validating XGBoost with VX features from bert...\n",
      "XGBoost cross-validation complete. Average RMSE: 97.19911746507822, Average MAPE: 64.52936858528918\n",
      "\n",
      "Cross-validating Linear Regression with VX+TX features from bert...\n",
      "Linear Regression cross-validation complete. Average RMSE: 105.97600135540225, Average MAPE: 62.77145550277063\n",
      "\n",
      "Cross-validating ElasticNet with VX+TX features from bert...\n",
      "ElasticNet cross-validation complete. Average RMSE: 105.53332099580284, Average MAPE: 69.01677358761617\n",
      "\n",
      "Cross-validating DecisionTree with VX+TX features from bert...\n",
      "DecisionTree cross-validation complete. Average RMSE: 92.12433319732803, Average MAPE: 62.473398945237236\n",
      "\n",
      "Cross-validating XGBoost with VX+TX features from bert...\n",
      "XGBoost cross-validation complete. Average RMSE: 70.89031130996565, Average MAPE: 39.99057768212106\n",
      "\n",
      "Loading features for language model: gpt2...\n",
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (47915, 32)\n",
      "Cross-validating Linear Regression with VX features from gpt2...\n",
      "Linear Regression cross-validation complete. Average RMSE: inf, Average MAPE: inf\n",
      "\n",
      "Cross-validating ElasticNet with VX features from gpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigore/ENV/lib64/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: overflow encountered in expm1\n",
      "/home/agrigore/ENV/lib64/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: overflow encountered in expm1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet cross-validation complete. Average RMSE: 118.48861009170032, Average MAPE: 79.36174039553539\n",
      "\n",
      "Cross-validating DecisionTree with VX features from gpt2...\n",
      "DecisionTree cross-validation complete. Average RMSE: 118.49278711700863, Average MAPE: 79.37938348365506\n",
      "\n",
      "Cross-validating XGBoost with VX features from gpt2...\n",
      "XGBoost cross-validation complete. Average RMSE: 118.50034867412435, Average MAPE: 79.37377169022444\n",
      "\n",
      "Cross-validating Linear Regression with VX+TX features from gpt2...\n",
      "Linear Regression cross-validation complete. Average RMSE: 2.132279110661904e+63, Average MAPE: 3.889603042325823e+60\n",
      "\n",
      "Cross-validating ElasticNet with VX+TX features from gpt2...\n",
      "ElasticNet cross-validation complete. Average RMSE: 105.53332099580284, Average MAPE: 69.01677358761617\n",
      "\n",
      "Cross-validating DecisionTree with VX+TX features from gpt2...\n",
      "DecisionTree cross-validation complete. Average RMSE: 90.26999057830906, Average MAPE: 65.24157379629993\n",
      "\n",
      "Cross-validating XGBoost with VX+TX features from gpt2...\n",
      "XGBoost cross-validation complete. Average RMSE: 70.49401187089984, Average MAPE: 43.66189798396442\n",
      "\n",
      "Loading features for language model: mt5...\n",
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (47915, 32)\n",
      "Cross-validating Linear Regression with VX features from mt5...\n",
      "Linear Regression cross-validation complete. Average RMSE: 111.86089267334822, Average MAPE: 71.91867266726682\n",
      "\n",
      "Cross-validating ElasticNet with VX features from mt5...\n",
      "ElasticNet cross-validation complete. Average RMSE: 118.48861009170032, Average MAPE: 79.36174039553539\n",
      "\n",
      "Cross-validating DecisionTree with VX features from mt5...\n",
      "DecisionTree cross-validation complete. Average RMSE: 146.35234188391465, Average MAPE: 131.01160410476731\n",
      "\n",
      "Cross-validating XGBoost with VX features from mt5...\n",
      "XGBoost cross-validation complete. Average RMSE: 109.20006456385985, Average MAPE: 72.30994828223257\n",
      "\n",
      "Cross-validating Linear Regression with VX+TX features from mt5...\n",
      "Linear Regression cross-validation complete. Average RMSE: 103.13619835072618, Average MAPE: 66.1629770831502\n",
      "\n",
      "Cross-validating ElasticNet with VX+TX features from mt5...\n",
      "ElasticNet cross-validation complete. Average RMSE: 105.53332099580284, Average MAPE: 69.01677358761617\n",
      "\n",
      "Cross-validating DecisionTree with VX+TX features from mt5...\n",
      "DecisionTree cross-validation complete. Average RMSE: 94.20218215117453, Average MAPE: 66.11293400310335\n",
      "\n",
      "Cross-validating XGBoost with VX+TX features from mt5...\n",
      "XGBoost cross-validation complete. Average RMSE: 72.6392850738571, Average MAPE: 43.67476413294895\n",
      "\n",
      "Loading features for language model: xlnet...\n",
      "Starting PCA...\n",
      "PCA complete.\n",
      "Reduced data shape: (47915, 32)\n",
      "Cross-validating Linear Regression with VX features from xlnet...\n",
      "Linear Regression cross-validation complete. Average RMSE: 104.99637980224472, Average MAPE: 68.42963543668827\n",
      "\n",
      "Cross-validating ElasticNet with VX features from xlnet...\n",
      "ElasticNet cross-validation complete. Average RMSE: 114.80425332155144, Average MAPE: 72.78965315507064\n",
      "\n",
      "Cross-validating DecisionTree with VX features from xlnet...\n",
      "DecisionTree cross-validation complete. Average RMSE: 126.96366253631145, Average MAPE: 103.77765402695141\n",
      "\n",
      "Cross-validating XGBoost with VX features from xlnet...\n",
      "XGBoost cross-validation complete. Average RMSE: 96.62644522509427, Average MAPE: 62.4081637965168\n",
      "\n",
      "Cross-validating Linear Regression with VX+TX features from xlnet...\n",
      "Linear Regression cross-validation complete. Average RMSE: 108.82789254828575, Average MAPE: 60.29612842871277\n",
      "\n",
      "Cross-validating ElasticNet with VX+TX features from xlnet...\n",
      "ElasticNet cross-validation complete. Average RMSE: 105.5333201700472, Average MAPE: 69.01677403288865\n",
      "\n",
      "Cross-validating DecisionTree with VX+TX features from xlnet...\n",
      "DecisionTree cross-validation complete. Average RMSE: 92.64781910790298, Average MAPE: 60.73861970479646\n",
      "\n",
      "Cross-validating XGBoost with VX+TX features from xlnet...\n",
      "XGBoost cross-validation complete. Average RMSE: 70.71120804272655, Average MAPE: 39.2007339286497\n",
      "\n",
      "   Language Model Features              Model  Average RMSE  Average MAPE\n",
      "0         roberta       VX  Linear Regression  1.048900e+02  7.070000e+01\n",
      "1         roberta       VX         ElasticNet  1.184900e+02  7.936000e+01\n",
      "2         roberta       VX       DecisionTree  1.303000e+02  1.111700e+02\n",
      "3         roberta       VX            XGBoost  9.845000e+01  6.823000e+01\n",
      "4         roberta    VX+TX  Linear Regression  1.013200e+02  6.558000e+01\n",
      "5         roberta    VX+TX         ElasticNet  1.055300e+02  6.902000e+01\n",
      "6         roberta    VX+TX       DecisionTree  9.280000e+01  6.404000e+01\n",
      "7         roberta    VX+TX            XGBoost  7.107000e+01  4.259000e+01\n",
      "8            bert       VX  Linear Regression  1.044400e+02  6.885000e+01\n",
      "9            bert       VX         ElasticNet  1.184900e+02  7.936000e+01\n",
      "10           bert       VX       DecisionTree  1.259200e+02  1.044900e+02\n",
      "11           bert       VX            XGBoost  9.720000e+01  6.453000e+01\n",
      "12           bert    VX+TX  Linear Regression  1.059800e+02  6.277000e+01\n",
      "13           bert    VX+TX         ElasticNet  1.055300e+02  6.902000e+01\n",
      "14           bert    VX+TX       DecisionTree  9.212000e+01  6.247000e+01\n",
      "15           bert    VX+TX            XGBoost  7.089000e+01  3.999000e+01\n",
      "16           gpt2       VX  Linear Regression           inf           inf\n",
      "17           gpt2       VX         ElasticNet  1.184900e+02  7.936000e+01\n",
      "18           gpt2       VX       DecisionTree  1.184900e+02  7.938000e+01\n",
      "19           gpt2       VX            XGBoost  1.185000e+02  7.937000e+01\n",
      "20           gpt2    VX+TX  Linear Regression  2.132279e+63  3.889603e+60\n",
      "21           gpt2    VX+TX         ElasticNet  1.055300e+02  6.902000e+01\n",
      "22           gpt2    VX+TX       DecisionTree  9.027000e+01  6.524000e+01\n",
      "23           gpt2    VX+TX            XGBoost  7.049000e+01  4.366000e+01\n",
      "24            mt5       VX  Linear Regression  1.118600e+02  7.192000e+01\n",
      "25            mt5       VX         ElasticNet  1.184900e+02  7.936000e+01\n",
      "26            mt5       VX       DecisionTree  1.463500e+02  1.310100e+02\n",
      "27            mt5       VX            XGBoost  1.092000e+02  7.231000e+01\n",
      "28            mt5    VX+TX  Linear Regression  1.031400e+02  6.616000e+01\n",
      "29            mt5    VX+TX         ElasticNet  1.055300e+02  6.902000e+01\n",
      "30            mt5    VX+TX       DecisionTree  9.420000e+01  6.611000e+01\n",
      "31            mt5    VX+TX            XGBoost  7.264000e+01  4.367000e+01\n",
      "32          xlnet       VX  Linear Regression  1.050000e+02  6.843000e+01\n",
      "33          xlnet       VX         ElasticNet  1.148000e+02  7.279000e+01\n",
      "34          xlnet       VX       DecisionTree  1.269600e+02  1.037800e+02\n",
      "35          xlnet       VX            XGBoost  9.663000e+01  6.241000e+01\n",
      "36          xlnet    VX+TX  Linear Regression  1.088300e+02  6.030000e+01\n",
      "37          xlnet    VX+TX         ElasticNet  1.055300e+02  6.902000e+01\n",
      "38          xlnet    VX+TX       DecisionTree  9.265000e+01  6.074000e+01\n",
      "39          xlnet    VX+TX            XGBoost  7.071000e+01  3.920000e+01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=50, n_jobs=1) \n",
    "}\n",
    "\n",
    "# List of language models\n",
    "language_models = ['roberta', 'bert', 'gpt2', 'mt5','xlnet']\n",
    "\n",
    "# language_models = ['xlnet']\n",
    "\n",
    "# Feature sets\n",
    "feature_sets = ['VX', 'TX', 'VX+TX']\n",
    "\n",
    "feature_sets = ['VX', 'VX+TX']\n",
    "\n",
    "# Function to compute the Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.expm1(y_true), np.expm1(y_pred)  # Apply expm1 before calculating the metrics\n",
    "    return np.mean(np.where(y_true != 0, np.abs((y_true - y_pred) / y_true), 0)) * 100\n",
    "\n",
    "# Define KFold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# Function to perform cross-validation\n",
    "def cross_validate(model, X, y, kf):\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Create a clone of the model to ensure that the model's initial state is preserved\n",
    "        model_clone = clone(model)\n",
    "        # Split the data\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Fit the model\n",
    "        model_clone.fit(X_train, y_train)\n",
    "        # Make predictions\n",
    "        y_pred = model_clone.predict(X_test)\n",
    "        # Calculate RMSE\n",
    "        mse_score = np.mean((np.expm1(y_test) - np.expm1(y_pred)) ** 2)\n",
    "        rmse_score = np.sqrt(mse_score)\n",
    "        rmse_scores.append(rmse_score)\n",
    "        # Calculate MAPE\n",
    "        mape_score = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        mape_scores.append(mape_score)\n",
    "    # Calculate average scores\n",
    "    average_rmse = np.mean(rmse_scores)\n",
    "    average_mape = np.mean(mape_scores)\n",
    "    return average_rmse, average_mape\n",
    "\n",
    "\n",
    "results = []\n",
    "y = np.log1p(DX)\n",
    "# Calculate cross-validation score for each model\n",
    "for language_model in language_models:\n",
    "    print(f\"Loading features for language model: {language_model}...\")\n",
    "    FX = load_features(language_model)[filtered]\n",
    "    VX = perform_pca(FX, 32)\n",
    "    for feature_set in feature_sets:\n",
    "        if feature_set == 'VX':\n",
    "            X = VX\n",
    "        elif feature_set == 'TX':\n",
    "            X = TX\n",
    "        elif feature_set == 'VX+TX':\n",
    "            X = np.concatenate([VX,TX],axis=1)\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"Cross-validating {model_name} with {feature_set} features from {language_model}...\")\n",
    "            average_rmse, average_mape = cross_validate(model, XES, YES, kf)\n",
    "            results.append([language_model, feature_set, model_name, average_rmse, average_mape])\n",
    "            print(f\"{model_name} cross-validation complete. Average RMSE: {average_rmse}, Average MAPE: {average_mape}\\n\")\n",
    "\n",
    "# Convert results to DataFrame for a nice table display\n",
    "results_df = pd.DataFrame(results, columns=['Language Model', 'Features', 'Model', 'Average RMSE', 'Average MAPE']).round(2)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "208a86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df.Features=='TX']['Language Model']='-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3920cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_feature_values(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df['Features'] = df['Features'].replace({'VX': 'LLM-features', 'TX': 'Report-features', 'VX+TX': 'LLM-features + Report-features'})\n",
    "    \n",
    "    # Replace 'Language Model' with '-' when 'Features' is 'Report-features'\n",
    "    df.loc[df['Features'] == 'Report-features', 'Language Model'] = '-'\n",
    "    \n",
    "    return df\n",
    "results_df = replace_feature_values(results_df.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0294730b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language Model</th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Average RMSE</th>\n",
       "      <th>Average MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.049000e+02</td>\n",
       "      <td>7.070000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.303000e+02</td>\n",
       "      <td>1.112000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>9.840000e+01</td>\n",
       "      <td>6.820000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.013000e+02</td>\n",
       "      <td>6.560000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.055000e+02</td>\n",
       "      <td>6.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>9.280000e+01</td>\n",
       "      <td>6.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>roberta</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.110000e+01</td>\n",
       "      <td>4.260000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.044000e+02</td>\n",
       "      <td>6.880000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.259000e+02</td>\n",
       "      <td>1.045000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>9.720000e+01</td>\n",
       "      <td>6.450000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.060000e+02</td>\n",
       "      <td>6.280000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.055000e+02</td>\n",
       "      <td>6.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>9.210000e+01</td>\n",
       "      <td>6.250000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.090000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2.132279e+63</td>\n",
       "      <td>3.889603e+60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.055000e+02</td>\n",
       "      <td>6.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>9.030000e+01</td>\n",
       "      <td>6.520000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.050000e+01</td>\n",
       "      <td>4.370000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.119000e+02</td>\n",
       "      <td>7.190000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.185000e+02</td>\n",
       "      <td>7.940000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.464000e+02</td>\n",
       "      <td>1.310000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.092000e+02</td>\n",
       "      <td>7.230000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.031000e+02</td>\n",
       "      <td>6.620000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.055000e+02</td>\n",
       "      <td>6.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>9.420000e+01</td>\n",
       "      <td>6.610000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mt5</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.260000e+01</td>\n",
       "      <td>4.370000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.050000e+02</td>\n",
       "      <td>6.840000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.148000e+02</td>\n",
       "      <td>7.280000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.270000e+02</td>\n",
       "      <td>1.038000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>9.660000e+01</td>\n",
       "      <td>6.240000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1.088000e+02</td>\n",
       "      <td>6.030000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1.055000e+02</td>\n",
       "      <td>6.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>9.260000e+01</td>\n",
       "      <td>6.070000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>LLM-features + Report-features</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.070000e+01</td>\n",
       "      <td>3.920000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Model                        Features              Model  \\\n",
       "0         roberta                    LLM-features  Linear Regression   \n",
       "1         roberta                    LLM-features         ElasticNet   \n",
       "2         roberta                    LLM-features       DecisionTree   \n",
       "3         roberta                    LLM-features            XGBoost   \n",
       "4         roberta  LLM-features + Report-features  Linear Regression   \n",
       "5         roberta  LLM-features + Report-features         ElasticNet   \n",
       "6         roberta  LLM-features + Report-features       DecisionTree   \n",
       "7         roberta  LLM-features + Report-features            XGBoost   \n",
       "8            bert                    LLM-features  Linear Regression   \n",
       "9            bert                    LLM-features         ElasticNet   \n",
       "10           bert                    LLM-features       DecisionTree   \n",
       "11           bert                    LLM-features            XGBoost   \n",
       "12           bert  LLM-features + Report-features  Linear Regression   \n",
       "13           bert  LLM-features + Report-features         ElasticNet   \n",
       "14           bert  LLM-features + Report-features       DecisionTree   \n",
       "15           bert  LLM-features + Report-features            XGBoost   \n",
       "16           gpt2                    LLM-features  Linear Regression   \n",
       "17           gpt2                    LLM-features         ElasticNet   \n",
       "18           gpt2                    LLM-features       DecisionTree   \n",
       "19           gpt2                    LLM-features            XGBoost   \n",
       "20           gpt2  LLM-features + Report-features  Linear Regression   \n",
       "21           gpt2  LLM-features + Report-features         ElasticNet   \n",
       "22           gpt2  LLM-features + Report-features       DecisionTree   \n",
       "23           gpt2  LLM-features + Report-features            XGBoost   \n",
       "24            mt5                    LLM-features  Linear Regression   \n",
       "25            mt5                    LLM-features         ElasticNet   \n",
       "26            mt5                    LLM-features       DecisionTree   \n",
       "27            mt5                    LLM-features            XGBoost   \n",
       "28            mt5  LLM-features + Report-features  Linear Regression   \n",
       "29            mt5  LLM-features + Report-features         ElasticNet   \n",
       "30            mt5  LLM-features + Report-features       DecisionTree   \n",
       "31            mt5  LLM-features + Report-features            XGBoost   \n",
       "32          xlnet                    LLM-features  Linear Regression   \n",
       "33          xlnet                    LLM-features         ElasticNet   \n",
       "34          xlnet                    LLM-features       DecisionTree   \n",
       "35          xlnet                    LLM-features            XGBoost   \n",
       "36          xlnet  LLM-features + Report-features  Linear Regression   \n",
       "37          xlnet  LLM-features + Report-features         ElasticNet   \n",
       "38          xlnet  LLM-features + Report-features       DecisionTree   \n",
       "39          xlnet  LLM-features + Report-features            XGBoost   \n",
       "\n",
       "    Average RMSE  Average MAPE  \n",
       "0   1.049000e+02  7.070000e+01  \n",
       "1   1.185000e+02  7.940000e+01  \n",
       "2   1.303000e+02  1.112000e+02  \n",
       "3   9.840000e+01  6.820000e+01  \n",
       "4   1.013000e+02  6.560000e+01  \n",
       "5   1.055000e+02  6.900000e+01  \n",
       "6   9.280000e+01  6.400000e+01  \n",
       "7   7.110000e+01  4.260000e+01  \n",
       "8   1.044000e+02  6.880000e+01  \n",
       "9   1.185000e+02  7.940000e+01  \n",
       "10  1.259000e+02  1.045000e+02  \n",
       "11  9.720000e+01  6.450000e+01  \n",
       "12  1.060000e+02  6.280000e+01  \n",
       "13  1.055000e+02  6.900000e+01  \n",
       "14  9.210000e+01  6.250000e+01  \n",
       "15  7.090000e+01  4.000000e+01  \n",
       "16           inf           inf  \n",
       "17  1.185000e+02  7.940000e+01  \n",
       "18  1.185000e+02  7.940000e+01  \n",
       "19  1.185000e+02  7.940000e+01  \n",
       "20  2.132279e+63  3.889603e+60  \n",
       "21  1.055000e+02  6.900000e+01  \n",
       "22  9.030000e+01  6.520000e+01  \n",
       "23  7.050000e+01  4.370000e+01  \n",
       "24  1.119000e+02  7.190000e+01  \n",
       "25  1.185000e+02  7.940000e+01  \n",
       "26  1.464000e+02  1.310000e+02  \n",
       "27  1.092000e+02  7.230000e+01  \n",
       "28  1.031000e+02  6.620000e+01  \n",
       "29  1.055000e+02  6.900000e+01  \n",
       "30  9.420000e+01  6.610000e+01  \n",
       "31  7.260000e+01  4.370000e+01  \n",
       "32  1.050000e+02  6.840000e+01  \n",
       "33  1.148000e+02  7.280000e+01  \n",
       "34  1.270000e+02  1.038000e+02  \n",
       "35  9.660000e+01  6.240000e+01  \n",
       "36  1.088000e+02  6.030000e+01  \n",
       "37  1.055000e+02  6.900000e+01  \n",
       "38  9.260000e+01  6.070000e+01  \n",
       "39  7.070000e+01  3.920000e+01  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5473b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "    df_avg = df.groupby(['Language Model','Features', 'Model'], as_index=False).mean()\n",
    "    \n",
    "    return df_avg\n",
    "results_df = calculate_average(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "667f5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(df):\n",
    "    df = df.copy()  # Make a copy of the DataFrame to avoid modifying the original\n",
    "    # Group by 'Features' and 'Model', then calculate mean for 'Average RMSE' and 'Average MAPE'\n",
    "    df_avg = df.groupby(['Language Model','Features', 'Model'], as_index=False).mean()\n",
    "    \n",
    "    return df_avg\n",
    "results_df = calculate_average(results_df)\n",
    "results_df.to_csv('results-LLM-32.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99fb3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hpelm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8d94ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
      "     |████████████████████████████████| 173.6 MB 17.9 MB/s                                        | 1.3 MB 5.0 MB/s eta 0:00:355.0 MB/s eta 0:00:34              | 10.6 MB 5.0 MB/s eta 0:00:33                        | 25.0 MB 5.0 MB/s eta 0:00:303 MB 5.0 MB/s eta 0:00:29�▊                         | 36.6 MB 5.0 MB/s eta 0:00:28          | 40.8 MB 5.0 MB/s eta 0:00:27:16                 | 51.6 MB 7.8 MB/s eta 0:00:16                 | 53.9 MB 7.8 MB/s eta 0:00:161615                | 60.5 MB 7.8 MB/s eta 0:00:15  |███████████▊                    | 63.6 MB 7.8 MB/s eta 0:00:15███                  | 75.9 MB 20.1 MB/s eta 0:00:05�██████████▉               | 91.3 MB 20.1 MB/s eta 0:00:05█████████████              | 97.3 MB 20.1 MB/s eta 0:00:04��█▎             | 98.9 MB 20.1 MB/s eta 0:00:04  |███████████████████▍            | 105.5 MB 20.1 MB/s eta 0:00:04    |███████████████████▊            | 107.1 MB 64.2 MB/s eta 0:00:02��██████████████████▌           | 111.2 MB 64.2 MB/s eta 0:00:01B 64.2 MB/s eta 0:00:01B 64.2 MB/s eta 0:00:01��████████▏       | 130.9 MB 64.2 MB/s eta 0:00:01█████▍       | 132.6 MB 64.2 MB/s eta 0:00:01��██████████████████████       | 135.6 MB 64.2 MB/s eta 0:00:01██████▎      | 137.3 MB 64.2 MB/s eta 0:00:01 7.9 MB/s eta 0:00:05 | 148.5 MB 7.9 MB/s eta 0:00:04 �█████████    | 152.3 MB 7.9 MB/s eta 0:00:03 ��████████▎   | 153.5 MB 7.9 MB/s eta 0:00:03 ��█████████   | 157.8 MB 7.9 MB/s eta 0:00:02 ��███████████████████▏  | 158.4 MB 7.9 MB/s eta 0:00:02 ��███████████████████▌  | 159.9 MB 7.9 MB/s eta 0:00:02 ��███████████████████▉  | 162.0 MB 7.9 MB/s eta 0:00:02  |██████████████████████████████▋ | 166.1 MB 7.9 MB/s eta 0:00:01 ��█████████████████████████▉ | 167.3 MB 7.9 MB/s eta 0:00:01 \n",
      "\u001b[?25hRequirement already satisfied: scipy in ./ENV/lib/python3.6/site-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: numpy in ./ENV/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98aded6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
